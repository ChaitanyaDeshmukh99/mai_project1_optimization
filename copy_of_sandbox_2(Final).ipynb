{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaitanyaDeshmukh99/mai_project1_optimization/blob/main/copy_of_sandbox_2(Final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5rH2nKyHMxg"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP9as0SOE31z",
        "outputId": "d62bc33e-94bc-49be-f0f8-6beb73bcea25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mai_project1_optimization' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    !git clone https://github.com/LeonLaumeyer/mai_project1_optimization.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IUVrsIRE2l1"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip3 install -r mai_project1_optimization/requirements.txt\n",
        "    !pip3 install optuna\n",
        "    !pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzDiD0vBASXm"
      },
      "outputs": [],
      "source": [
        "!pip3 install accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LFYEJGNE_-l"
      },
      "outputs": [],
      "source": [
        "!pip3 install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkD57Ur6E2l2",
        "outputId": "e6b0db0b-8bab-454b-e189-fbe55eb93c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models\n",
        "from torchvision.models import *\n",
        "from plotly import express as px\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "if(IN_COLAB):\n",
        "    from mai_project1_optimization.modules.dataset import IntelImageClassificationDataset\n",
        "    from mai_project1_optimization.modules.utility import NotebookPlotter, InferenceSession, Evaluator, ISO_time, apply_pruning\n",
        "    from mai_project1_optimization.modules.trainer import Trainer\n",
        "    from mai_project1_optimization.modules.optuna_optimizer import OptunaTuner\n",
        "    from mai_project1_optimization.modules.optuna_monashara import run_optuna\n",
        "else:\n",
        "    from modules.dataset import IntelImageClassificationDataset\n",
        "    from modules.utility import NotebookPlotter, InferenceSession, Evaluator, ISO_time, apply_pruning\n",
        "    from modules.trainer import Trainer\n",
        "    from modules.optuna_optimizer import OptunaTuner\n",
        "    from modules.optuna_monashara import run_optuna\n",
        "\n",
        "torch.manual_seed(1)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "def set_seed(seed=1):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True  # for reproducibility\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Removed support for Tensor Units\n",
        "# torch.backends.cudnn.allow_tf32 = True\n",
        "# torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbHgev5PE2l3"
      },
      "source": [
        "https://www.kaggle.com/datasets/puneet6060/intel-image-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3go5RaM8E2l3"
      },
      "outputs": [],
      "source": [
        "# labels, values = zip(*Counter([item[1] for item in dataset.train_dataset]).items())\n",
        "# fig = px.bar(x=labels, y=values, labels={'x': 'Categories', 'y': 'Counts'}, title='Distribution of Classes')\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjZypu8jE2l3"
      },
      "source": [
        "| n | label |\n",
        "| --- | --- |\n",
        "| 0 | buildings |\n",
        "| 1 | forest |\n",
        "| 2 | glacier |\n",
        "| 3 | mountain |\n",
        "| 4 | sea |\n",
        "| 5 | street |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EJgLtsTE2l4",
        "outputId": "0cf0b3eb-2066-4448-cbc1-ed73f35e5424"
      },
      "source": [
        "NotebookPlotter.plot_dataset_item_interactive(dataset.train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zDPzrOPHMyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de90d337-2130-4f85-f87d-9d0f00e5698c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n",
            "100%|██████████| 4.73M/4.73M [00:00<00:00, 57.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "choice = 1 # 1,2,3\n",
        "freezeLayer = False\n",
        "prune_model = False\n",
        "USE_OPTUNA = False\n",
        "OPTUNA_MO = False\n",
        "\n",
        "if choice != 5:\n",
        "    dataset = IntelImageClassificationDataset(resize=(150,150))\n",
        "else:\n",
        "    dataset = IntelImageClassificationDataset(resize=(384,384))\n",
        "\n",
        "# 80% train, 20% validation for training Optuna\n",
        "train_size = int(0.8 * len(dataset.train_dataset))\n",
        "val_size = len(dataset.train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(dataset.train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(1))\n",
        "\n",
        "def build_model():\n",
        "\n",
        "  # SqueezeNet 1.1\n",
        "  if choice == 1:\n",
        "      model = models.squeezenet1_1(weights=SqueezeNet1_1_Weights.DEFAULT)\n",
        "      num_features = model.classifier[1].in_channels\n",
        "      kernel_size = model.classifier[1].kernel_size\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.classifier[1] = nn.Conv2d(num_features, 6, kernel_size)\n",
        "\n",
        "\n",
        "  # MobileNetV2\n",
        "  elif choice == 2:\n",
        "      model = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
        "      num_features = model.classifier[1].in_features\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.classifier[1] = nn.Linear(num_features, 6)\n",
        "\n",
        "  # MobileNetV3 Small\n",
        "  elif choice == 3:\n",
        "      model = models.mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
        "      num_features = model.classifier[3].in_features\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.classifier[3] = nn.Linear(num_features, 6)\n",
        "\n",
        "  # MobileNetV3 Large\n",
        "  elif choice == 4:\n",
        "      model = models.mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n",
        "      num_features = model.classifier[3].in_features\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.classifier[3] = nn.Linear(num_features, 6)\n",
        "\n",
        "  # VisionTransformer Base 16\n",
        "  elif choice == 5:\n",
        "      model = models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1)\n",
        "      num_features = model.heads[0].in_features\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.heads[0] = nn.Linear(num_features, 6)\n",
        "\n",
        "  if prune_model:\n",
        "    model = apply_pruning(model, amount=0.3)\n",
        "\n",
        "  return model\n",
        "\n",
        "if USE_OPTUNA:\n",
        "    tuner = OptunaTuner(\n",
        "        model_fn=build_model,\n",
        "        train_dataset=train_subset,\n",
        "        val_dataset=val_subset,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    study = tuner.run(n_trials=10, seed=1)\n",
        "    print(\"Best trial parameters:\", study.best_trial.params)\n",
        "\n",
        "    best_params = study.best_trial.params\n",
        "    model = build_model()\n",
        "    dataloader = DataLoader(train_subset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
        "    trainer = Trainer(model=model, lr=best_params[\"lr\"], device=DEVICE)\n",
        "    epochs = best_params[\"epochs\"]\n",
        "\n",
        "elif OPTUNA_MO:\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    best_params, best_model_state, study = run_optuna(\n",
        "        model=model,\n",
        "        train_subset=train_subset,\n",
        "        val_subset=val_subset,\n",
        "        TrainerClass=Trainer,\n",
        "        n_trials=10,\n",
        "        seed=1\n",
        "    )\n",
        "\n",
        "    print(\"▶ Per-epoch validation accuracy (best trial):\")\n",
        "    best_trial = study.best_trial\n",
        "    for epoch, acc in sorted(best_trial.intermediate_values.items()):\n",
        "        print(f\"   Epoch {epoch:2d}: {acc * 100:.2f}%\")\n",
        "\n",
        "    print(f\"\\n▶ Best hyperparameters: {best_params}\")\n",
        "    print(f\"▶ Best overall accuracy: {study.best_value * 100:.2f}%\")\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    dataloader = DataLoader(\n",
        "        dataset.train_dataset,\n",
        "        batch_size=best_params[\"BS_SUGGEST\"],\n",
        "        shuffle=True\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        lr=best_params[\"LR_SUGGEST\"],\n",
        "        device=DEVICE\n",
        "    )\n",
        "    epochs = best_params[\"EPOCHS\"]\n",
        "\n",
        "else:\n",
        "    model = build_model()\n",
        "    dataloader = DataLoader(dataset.train_dataset, batch_size=32, shuffle=True)\n",
        "    trainer = Trainer(model=model, lr=8.841926348917726e-05, device=DEVICE)\n",
        "    epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b47fad2c0cf84e31af13843c327a2a4a",
            "ed1b22f7e4aa4b4baa9e3da6ff8027e2",
            "e8fe649caef4415eb4a86d1b6c67706f",
            "8a4af1629c524083a1ad840eff40628f",
            "a5878287dbc848e68c8cc2f05ffb95e7",
            "6d939b33e7a043e2adfdb212eaedf952",
            "df0d47bc695c42329f51f597baeb3caa",
            "011d08ab02544f9195d68a452ad7a469",
            "be63468895e74e8cb4de3439512c30df",
            "e92f2bb1dce4482583148380f2f1ae6e",
            "77f6ad95c79d4f9eacdad8a925dcedc4"
          ]
        },
        "id": "XW3sIV9KE2l4",
        "outputId": "b00cd17a-6592-4175-895d-829b0916b751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py:266: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b47fad2c0cf84e31af13843c327a2a4a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load(f\"checkpoints/.pt\"))\n",
        "trainer.train(dataloader, epochs=epochs, silent=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VESPNHBME2l4"
      },
      "outputs": [],
      "source": [
        "session = InferenceSession(model)\n",
        "output = session(torch.stack(tuple(item[0] for item in dataset.test_dataset)))\n",
        "Evaluator.acc(output, torch.tensor(tuple(item[1] for item in dataset.test_dataset))).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO9K7B_yE2l5"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), f\"checkpoints/{model.__class__.__name__}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method No 1\n",
        "#1) Efficient GPU memory management, including releasing unused memory\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiMpwrBp0vFf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rq8QAzo_GMD"
      },
      "outputs": [],
      "source": [
        "# Method No 1\n",
        "#1) Efficient GPU memory management, including releasing unused memory\n",
        "\n",
        "\n",
        "def release_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        print(\"GPU memory released.\")\n",
        "    else:\n",
        "        print(\"No GPU available to release memory.\")\n",
        "\n",
        "release_gpu_memory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method No 2\n",
        "#2) Executing asynchronous GPU operations and using non-blocking memory transfers"
      ],
      "metadata": {
        "id": "oWKHLgGw0lbc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YyjulqdMO4s"
      },
      "outputs": [],
      "source": [
        "# Method No 2\n",
        "#2) Executing asynchronous GPU operations and using non-blocking memory transfers\n",
        "dataloader = DataLoader(\n",
        "    dataset.train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "trainer = Trainer(model=model, lr=8.841926348917726e-05, device=DEVICE)\n",
        "epochs = 25\n",
        "\n",
        "\n",
        "trainer.train(dataloader, epochs=epochs, silent=False)\n",
        "session = InferenceSession(model)\n",
        "\n",
        "test_inputs = torch.stack(tuple(item[0] for item in dataset.test_dataset)).to(DEVICE, non_blocking=True)\n",
        "test_labels = torch.tensor(tuple(item[1] for item in dataset.test_dataset)).to(DEVICE, non_blocking=True)\n",
        "\n",
        "output = session(test_inputs)\n",
        "\n",
        "Evaluator.acc(output, test_labels).item()"
      ]
    },
    {
      "source": [
        "# Profiler Code\n",
        "import torch\n",
        "import torch.profiler\n",
        "\n",
        "\n",
        "sample_input, _ = next(iter(dataloader))\n",
        "sample_input = sample_input.to(DEVICE)\n",
        "\n",
        "\n",
        "with torch.profiler.profile(\n",
        "    activities=[\n",
        "        torch.profiler.ProfilerActivity.CPU,\n",
        "        torch.profiler.ProfilerActivity.CUDA\n",
        "    ],\n",
        "    record_shapes=True,\n",
        "\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    model(sample_input)\n",
        "\n",
        "prof.export_chrome_trace(\"model_profile.json\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iaZLYzjObhaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EqKgefA8ydLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model_profile.json\")\n"
      ],
      "metadata": {
        "id": "Ko0-itrqWx3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DVmLcpx2yeBr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b47fad2c0cf84e31af13843c327a2a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed1b22f7e4aa4b4baa9e3da6ff8027e2",
              "IPY_MODEL_e8fe649caef4415eb4a86d1b6c67706f",
              "IPY_MODEL_8a4af1629c524083a1ad840eff40628f"
            ],
            "layout": "IPY_MODEL_a5878287dbc848e68c8cc2f05ffb95e7"
          }
        },
        "ed1b22f7e4aa4b4baa9e3da6ff8027e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d939b33e7a043e2adfdb212eaedf952",
            "placeholder": "​",
            "style": "IPY_MODEL_df0d47bc695c42329f51f597baeb3caa",
            "value": "  0%"
          }
        },
        "e8fe649caef4415eb4a86d1b6c67706f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011d08ab02544f9195d68a452ad7a469",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be63468895e74e8cb4de3439512c30df",
            "value": 0
          }
        },
        "8a4af1629c524083a1ad840eff40628f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92f2bb1dce4482583148380f2f1ae6e",
            "placeholder": "​",
            "style": "IPY_MODEL_77f6ad95c79d4f9eacdad8a925dcedc4",
            "value": " 0/25 [00:00&lt;?, ?it/s]"
          }
        },
        "a5878287dbc848e68c8cc2f05ffb95e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d939b33e7a043e2adfdb212eaedf952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0d47bc695c42329f51f597baeb3caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "011d08ab02544f9195d68a452ad7a469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be63468895e74e8cb4de3439512c30df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e92f2bb1dce4482583148380f2f1ae6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f6ad95c79d4f9eacdad8a925dcedc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}